{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing CMU\n",
    "## 32khz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./TestData',exist_ok=True)\n",
    "os.makedirs('./TrainData',exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a7aff1b1bb44b8a5b6db68ac620dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1131), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab043e7407c42f3a98dd5b40d752dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1114), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2715c17cef451b9eb1135fdbd74014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1132), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for drt in ['./cmu_us_bdl_arctic/orig/','./cmu_us_jmk_arctic/orig/','./cmu_us_slt_arctic/orig/']:\n",
    "    os.makedirs(drt[:-5] + 'merge/',exist_ok=True)\n",
    "    files = os.listdir(drt)\n",
    "    for file in tqdm_notebook(files):\n",
    "        x,sr = librosa.load(drt + file,sr=None,mono=False)\n",
    "        x = librosa.resample(x,sr,16000)\n",
    "        sf.write(drt[:-5] + 'merge/' + file, x.T,16000, format='WAV', endian='LITTLE', subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./TestData/CMU',exist_ok=True)\n",
    "os.makedirs('./TrainData/CMU',exist_ok = True)\n",
    "for drt in ['./cmu_us_bdl_arctic/merge/','./cmu_us_jmk_arctic/merge/','./cmu_us_slt_arctic/merge/']:\n",
    "    files = os.listdir(drt)\n",
    "    for file in files:\n",
    "        if file[7]=='a':\n",
    "            shutil.copy2(drt+file, './TrainData/CMU/'+drt[9:13]+file)\n",
    "        if file[7]=='b':\n",
    "            shutil.copy2(drt + file,'./TestData/CMU/'+drt[9:13]+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing saarburkcen\n",
    "## 50khz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(speech,egg):\n",
    "    assert len(speech) == len(egg)\n",
    "    merged = np.zeros((2,len(speech)))\n",
    "    merged[0,:] = speech\n",
    "    merged[1,:] = egg\n",
    "    return merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(num):\n",
    "    for name in ['phrase','a_h','a_l','a_lhl','a_n','i_h','i_l','i_lhl','i_n','u_h','u_l','u_lhl','u_n']:\n",
    "        if os.path.exists('./saarbrucken/export/%d-%s.wav'%(num,name)) and os.path.exists('./saarbrucken/export/%d-%s-egg.wav'%(num,name)):\n",
    "            if not os.path.exists('./saarbrucken/merge/%d-%s.wav'%(num,name)):\n",
    "                n_iau,sr = librosa.load('./saarbrucken/export/%d-%s.wav'%(num,name),sr=None)\n",
    "                n_iau_egg,sr = librosa.load('./saarbrucken/export/%d-%s-egg.wav'%(num,name),sr=None)\n",
    "\n",
    "                merged = merge(n_iau,n_iau_egg)\n",
    "                merged = librosa.resample(merged,sr,16000)\n",
    "                sf.write('./saarbrucken/merge/%d-%s.wav'%(num,name), merged.T,16000, format='WAV', endian='LITTLE', subtype='PCM_16')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./saarbrucken_metadata.csv',engine='python')\n",
    "l = os.listdir('./saarbrucken/export/')\n",
    "n=[]\n",
    "for file in l:\n",
    "    num = int(file.split('-')[0])\n",
    "    if not num in n:\n",
    "        n.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(v):\n",
    "    if v in n:\n",
    "        return True\n",
    "    return False\n",
    "df = df[df['ID'].apply(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61662915ea4a65a10192d48739766b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2042), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pool = Pool(6)\n",
    "# pool.map(save,n)\n",
    "os.makedirs('./saarbrucken/merge',exist_ok=True)\n",
    "for num in tqdm_notebook(n):\n",
    "    save(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153 889\n",
      "426 261\n",
      "727 628\n"
     ]
    }
   ],
   "source": [
    "df_W = df[df.G == 'w']\n",
    "df_M = df[df.G == 'm']\n",
    "\n",
    "print(len(df_W),len(df_M))\n",
    "print(len(df_W[df_W['T']=='n']),len(df_M[df_M['T'] =='n']))\n",
    "print(len(df_W[df_W['T'] =='p']),len(df_M[df_M['T'] =='p']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ddf76aecf3427fb14ce7f35eb58e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2042), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pathology 686 Train, 669 Test\n"
     ]
    }
   ],
   "source": [
    "normal = df[df['T'] == 'n']\n",
    "Pathology = df[df['T'] == 'p']\n",
    "# Pathology_w = Pathology[Pathology['G'] == 'w']\n",
    "# Pathology_m = Pathology[Pathology['G'] == 'm']\n",
    "l = os.listdir('./saarbrucken/merge')\n",
    "os.makedirs('./TrainData/saarbrucken/',exist_ok=True)\n",
    "os.makedirs('./TestData/saarbrucken/',exist_ok=True)\n",
    "cnt1,cnt2 = 0,0\n",
    "for num in tqdm_notebook(n) :\n",
    "    if num in normal.ID.values:\n",
    "        for name in ['phrase','a_h','a_l','a_lhl','a_n','i_h','i_l','i_lhl','i_n','u_h','u_l','u_lhl','u_n']:\n",
    "            try:\n",
    "                shutil.copy2('./saarbrucken/merge/%d-%s.wav'%(num,name),'./TrainData/saarbrucken/%d-%s.wav'%(num,name))\n",
    "            except:\n",
    "                pass\n",
    "    elif num in Pathology.ID.values:\n",
    "        if np.random.uniform()<0.5:\n",
    "            cnt1 +=1\n",
    "            for name in ['phrase','a_h','a_l','a_lhl','a_n','i_h','i_l','i_lhl','i_n','u_h','u_l','u_lhl','u_n']:\n",
    "                try:\n",
    "                    shutil.copy2('./saarbrucken/merge/%d-%s.wav'%(num,name),'./TrainData/saarbrucken/%d-%s.wav'%(num,name))\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            cnt2 +=1\n",
    "            for name in ['phrase','a_h','a_l','a_lhl','a_n','i_h','i_l','i_lhl','i_n','u_h','u_l','u_lhl','u_n']:\n",
    "                try:\n",
    "                    shutil.copy2('./saarbrucken/merge/%d-%s.wav'%(num,name),'./TestData/saarbrucken/%d-%s.wav'%(num,name))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "print(\"Pathology %d Train, %d Test\"%(cnt1,cnt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 695)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt1,cnt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing these_AlexisMichaud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('./TestData/Alexis',exist_ok=True)\n",
    "os.makedirs('./Alexis',exist_ok = True)\n",
    "os.makedirs('./TrainData/Alexis',exist_ok = True)\n",
    "for file in os.listdir('./these_AlexisMichaud/'):\n",
    "    if file[-5] == 'A':\n",
    "        Speech,sr = librosa.load('./these_AlexisMichaud/' + file)\n",
    "        EGG,sr = librosa.load('./these_AlexisMichaud/' + file[:-5]+'E.wav')\n",
    "        merged = merge(Speech,EGG)\n",
    "        merged = librosa.resample(merged,sr,16000)\n",
    "        sf.write('./Alexis/'+file[:-6]+'.wav', merged.T,16000, format='WAV', endian='LITTLE', subtype='PCM_16')\n",
    "        shutil.copy2('./Alexis/'+file[:-6]+'.wav','./TrainData/Alexis/'+file[:-5]+'.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Childers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f09146b623d4ebd93316bf5b79577fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('./childer/merge',exist_ok = True)\n",
    "os.makedirs('./TrainData/Childer',exist_ok=True)\n",
    "\n",
    "for drt in ['./childer/NORMAL_F/','./childer/NORMAL_M/']:\n",
    "    for p in tqdm_notebook(os.listdir(drt)):\n",
    "        for file in os.listdir(drt+p):\n",
    "            if file[-5]=='S':\n",
    "                try:\n",
    "                    Speech = np.loadtxt(os.path.join(drt+p,file),delimiter = \"::\",dtype=np.int16)/(2<<15)\n",
    "                    EGG = np.loadtxt(os.path.join(drt+p,file[:-5]+'E.DAT'),delimiter = \"::\",dtype=np.int16)/(2<<15)\n",
    "                \n",
    "                    assert Speech.shape[0] == EGG.shape[0]\n",
    "\n",
    "                    merged = merge(Speech,EGG)\n",
    "                    merged = librosa.resample(merged,10000,16000)\n",
    "                    sf.write('./childer/merge/'+file[:-5]+'.wav',merged.T,16000, format='WAV', endian='LITTLE', subtype='PCM_16')\n",
    "                    shutil.copy2('./childer/merge/'+file[:-5]+'.wav','./TrainData/Childer/'+file[:-5]+'.wav')\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('./TrainData/normal_noise/'):\n",
    "    x,sr = librosa.load('./TrainData/norma l_noise/'+file,sr=16000)\n",
    "    sf.write('./TrainData/normal_noise/'+file,x,16000, format='WAV', endian='LITTLE', subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fc5726489147778dc174d9b3f1f4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f313afa9f184ad4a02c867964d5d543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for drt in tqdm_notebook(os.listdir('./DSD100/Sources/Dev/')):\n",
    "    for file in ['bass.wav','drums.wav','other.wav']:\n",
    "        x,sr = librosa.load(os.path.join('./DSD100/Sources/Dev/'+drt,file),sr=16000)\n",
    "        tmp = np.array([])\n",
    "        itvs = librosa.effects.split(x,frame_length = 128, hop_length = 64,top_db = 20)\n",
    "        for st,ed in itvs:\n",
    "            tmp = np.concatenate((tmp,x[st:ed]))\n",
    "        sf.write('./TrainData/musical_noise/'+file[:-4]+'_%d.wav'%i,tmp,16000, format='WAV', endian='LITTLE', subtype='PCM_16')\n",
    "    i+=1\n",
    "\n",
    "for drt in tqdm_notebook(os.listdir('./DSD100/Sources/Test/')):\n",
    "    for file in ['bass.wav','drums.wav','other.wav']:\n",
    "        x,sr = librosa.load(os.path.join('./DSD100/Sources/Test/'+drt,file),sr=16000)\n",
    "        tmp = np.array([])\n",
    "        itvs = librosa.effects.split(x,frame_length = 128, hop_length = 64,top_db = 20)\n",
    "        for st,ed in itvs:\n",
    "            tmp = np.concatenate((tmp,x[st:ed]))\n",
    "        sf.write('./TrainData/musical_noise/'+file[:-4]+'_%d.wav'%i,tmp,16000, format='WAV', endian='LITTLE', subtype='PCM_16')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
