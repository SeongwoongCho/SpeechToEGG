{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.onnx\n",
    "from efficientunet import *\n",
    "from efficientunet.layers import BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientUnet(\n",
       "  (encoder): Encoder(\n",
       "    (stem_conv): Conv2dSamePadding(\n",
       "      2, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 1, 1), value=0.0)\n",
       "    )\n",
       "    (stem_batch_norm): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (stem_swish): Swish()\n",
       "    (blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          528, 528, kernel_size=(5, 5), stride=[1, 1], groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=[2, 2], groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          1248, 1248, kernel_size=(3, 3), stride=[1, 1], groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (swish): Swish()\n",
       "        (_expand_conv): Conv2dSamePadding(\n",
       "          352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dSamePadding(\n",
       "          2112, 2112, kernel_size=(3, 3), stride=(1, 1), groups=2112, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dSamePadding(\n",
       "          2112, 88, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dSamePadding(\n",
       "          88, 2112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dSamePadding(\n",
       "          2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (head_conv): Conv2dSamePadding(\n",
       "      352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (head_batch_norm): BatchNorm2d(1408, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (head_swish): Swish()\n",
       "  )\n",
       "  (up_conv1): SequentialConvTranspose2d(\n",
       "    (conv): Conv2d(1408, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "  )\n",
       "  (double_conv1): Sequential(\n",
       "    (0): Conv2d(600, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv2): SequentialConvTranspose2d(\n",
       "    (conv): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "  )\n",
       "  (double_conv2): Sequential(\n",
       "    (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv3): SequentialConvTranspose2d(\n",
       "    (conv): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "  )\n",
       "  (double_conv3): Sequential(\n",
       "    (0): Conv2d(152, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv4): SequentialConvTranspose2d(\n",
       "    (conv): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "  )\n",
       "  (double_conv4): Sequential(\n",
       "    (0): Conv2d(80, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv_input): SequentialConvTranspose2d(\n",
       "    (conv): Conv2d(64, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "  )\n",
       "  (double_conv_input): Sequential(\n",
       "    (0): Conv2d(34, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_efficientunet_b2(out_channels=3, concat_input=True, pretrained=False, bn = BatchNorm2d)\n",
    "# model.load_state_dict(torch.load('../models/masked/exp6-re/best_5761.pth',map_location = lambaada storage, loc: storage))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((1, 2, 257, 64),requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.13267183303833 4.76837158203125e-06 0.09547758102416992 6.723403930664062e-05 0.030711889266967773 0.4519362449645996\n",
      "CPU times: user 3min 54s, sys: 437 ms, total: 3min 54s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    torch_out = model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../efficientunet/efficientunet.py:76: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if shape_list not in shapes:\n",
      "../efficientunet/layers.py:204: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x_new[:,:,::2,::2] = x.clone()\n",
      "../efficientunet/layers.py:205: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x_new[:,:,1::2,::2] = x.clone()\n",
      "../efficientunet/layers.py:206: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x_new[:,:,::2,1::2] = x.clone()\n",
      "../efficientunet/layers.py:207: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x_new[:,:,1::2,1::2] = x.clone()\n",
      "../efficientunet/efficientunet.py:201: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x[:,0,:,:] = torch.clamp(x[:,0,:,:].clone(),-12,7) ## clamp magnitude channel\n",
      "../efficientunet/efficientunet.py:202: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x[:,1,:,:] = torch.clamp(x[:,1,:,:].clone(),-np.pi,np.pi) ## clamp phase channel\n",
      "../efficientunet/efficientunet.py:203: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
      "  x[:,2,:,:] = torch.clamp(x[:,2,:,:].clone(),-10,10) ## clamp mask channel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 2, 257, 64),\n",
      "      %encoder.stem_conv.weight : Float(32, 2, 3, 3),\n",
      "      %encoder.stem_batch_norm.weight : Float(32),\n",
      "      %encoder.stem_batch_norm.bias : Float(32),\n",
      "      %encoder.stem_batch_norm.running_mean : Float(32),\n",
      "      %encoder.stem_batch_norm.running_var : Float(32),\n",
      "      %encoder.stem_batch_norm.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.0._depthwise_conv.weight : Float(32, 1, 3, 3),\n",
      "      %encoder.blocks.0._bn1.weight : Float(32),\n",
      "      %encoder.blocks.0._bn1.bias : Float(32),\n",
      "      %encoder.blocks.0._bn1.running_mean : Float(32),\n",
      "      %encoder.blocks.0._bn1.running_var : Float(32),\n",
      "      %encoder.blocks.0._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.0._se_reduce.weight : Float(8, 32, 1, 1),\n",
      "      %encoder.blocks.0._se_reduce.bias : Float(8),\n",
      "      %encoder.blocks.0._se_expand.weight : Float(32, 8, 1, 1),\n",
      "      %encoder.blocks.0._se_expand.bias : Float(32),\n",
      "      %encoder.blocks.0._project_conv.weight : Float(16, 32, 1, 1),\n",
      "      %encoder.blocks.0._bn2.weight : Float(16),\n",
      "      %encoder.blocks.0._bn2.bias : Float(16),\n",
      "      %encoder.blocks.0._bn2.running_mean : Float(16),\n",
      "      %encoder.blocks.0._bn2.running_var : Float(16),\n",
      "      %encoder.blocks.0._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.1._expand_conv.weight : Float(96, 16, 1, 1),\n",
      "      %encoder.blocks.1._bn0.weight : Float(96),\n",
      "      %encoder.blocks.1._bn0.bias : Float(96),\n",
      "      %encoder.blocks.1._bn0.running_mean : Float(96),\n",
      "      %encoder.blocks.1._bn0.running_var : Float(96),\n",
      "      %encoder.blocks.1._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.1._depthwise_conv.weight : Float(96, 1, 3, 3),\n",
      "      %encoder.blocks.1._bn1.weight : Float(96),\n",
      "      %encoder.blocks.1._bn1.bias : Float(96),\n",
      "      %encoder.blocks.1._bn1.running_mean : Float(96),\n",
      "      %encoder.blocks.1._bn1.running_var : Float(96),\n",
      "      %encoder.blocks.1._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.1._se_reduce.weight : Float(4, 96, 1, 1),\n",
      "      %encoder.blocks.1._se_reduce.bias : Float(4),\n",
      "      %encoder.blocks.1._se_expand.weight : Float(96, 4, 1, 1),\n",
      "      %encoder.blocks.1._se_expand.bias : Float(96),\n",
      "      %encoder.blocks.1._project_conv.weight : Float(24, 96, 1, 1),\n",
      "      %encoder.blocks.1._bn2.weight : Float(24),\n",
      "      %encoder.blocks.1._bn2.bias : Float(24),\n",
      "      %encoder.blocks.1._bn2.running_mean : Float(24),\n",
      "      %encoder.blocks.1._bn2.running_var : Float(24),\n",
      "      %encoder.blocks.1._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.2._expand_conv.weight : Float(144, 24, 1, 1),\n",
      "      %encoder.blocks.2._bn0.weight : Float(144),\n",
      "      %encoder.blocks.2._bn0.bias : Float(144),\n",
      "      %encoder.blocks.2._bn0.running_mean : Float(144),\n",
      "      %encoder.blocks.2._bn0.running_var : Float(144),\n",
      "      %encoder.blocks.2._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.2._depthwise_conv.weight : Float(144, 1, 3, 3),\n",
      "      %encoder.blocks.2._bn1.weight : Float(144),\n",
      "      %encoder.blocks.2._bn1.bias : Float(144),\n",
      "      %encoder.blocks.2._bn1.running_mean : Float(144),\n",
      "      %encoder.blocks.2._bn1.running_var : Float(144),\n",
      "      %encoder.blocks.2._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.2._se_reduce.weight : Float(6, 144, 1, 1),\n",
      "      %encoder.blocks.2._se_reduce.bias : Float(6),\n",
      "      %encoder.blocks.2._se_expand.weight : Float(144, 6, 1, 1),\n",
      "      %encoder.blocks.2._se_expand.bias : Float(144),\n",
      "      %encoder.blocks.2._project_conv.weight : Float(24, 144, 1, 1),\n",
      "      %encoder.blocks.2._bn2.weight : Float(24),\n",
      "      %encoder.blocks.2._bn2.bias : Float(24),\n",
      "      %encoder.blocks.2._bn2.running_mean : Float(24),\n",
      "      %encoder.blocks.2._bn2.running_var : Float(24),\n",
      "      %encoder.blocks.2._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.3._expand_conv.weight : Float(144, 24, 1, 1),\n",
      "      %encoder.blocks.3._bn0.weight : Float(144),\n",
      "      %encoder.blocks.3._bn0.bias : Float(144),\n",
      "      %encoder.blocks.3._bn0.running_mean : Float(144),\n",
      "      %encoder.blocks.3._bn0.running_var : Float(144),\n",
      "      %encoder.blocks.3._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.3._depthwise_conv.weight : Float(144, 1, 5, 5),\n",
      "      %encoder.blocks.3._bn1.weight : Float(144),\n",
      "      %encoder.blocks.3._bn1.bias : Float(144),\n",
      "      %encoder.blocks.3._bn1.running_mean : Float(144),\n",
      "      %encoder.blocks.3._bn1.running_var : Float(144),\n",
      "      %encoder.blocks.3._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.3._se_reduce.weight : Float(6, 144, 1, 1),\n",
      "      %encoder.blocks.3._se_reduce.bias : Float(6),\n",
      "      %encoder.blocks.3._se_expand.weight : Float(144, 6, 1, 1),\n",
      "      %encoder.blocks.3._se_expand.bias : Float(144),\n",
      "      %encoder.blocks.3._project_conv.weight : Float(40, 144, 1, 1),\n",
      "      %encoder.blocks.3._bn2.weight : Float(40),\n",
      "      %encoder.blocks.3._bn2.bias : Float(40),\n",
      "      %encoder.blocks.3._bn2.running_mean : Float(40),\n",
      "      %encoder.blocks.3._bn2.running_var : Float(40),\n",
      "      %encoder.blocks.3._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.4._expand_conv.weight : Float(240, 40, 1, 1),\n",
      "      %encoder.blocks.4._bn0.weight : Float(240),\n",
      "      %encoder.blocks.4._bn0.bias : Float(240),\n",
      "      %encoder.blocks.4._bn0.running_mean : Float(240),\n",
      "      %encoder.blocks.4._bn0.running_var : Float(240),\n",
      "      %encoder.blocks.4._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.4._depthwise_conv.weight : Float(240, 1, 5, 5),\n",
      "      %encoder.blocks.4._bn1.weight : Float(240),\n",
      "      %encoder.blocks.4._bn1.bias : Float(240),\n",
      "      %encoder.blocks.4._bn1.running_mean : Float(240),\n",
      "      %encoder.blocks.4._bn1.running_var : Float(240),\n",
      "      %encoder.blocks.4._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.4._se_reduce.weight : Float(10, 240, 1, 1),\n",
      "      %encoder.blocks.4._se_reduce.bias : Float(10),\n",
      "      %encoder.blocks.4._se_expand.weight : Float(240, 10, 1, 1),\n",
      "      %encoder.blocks.4._se_expand.bias : Float(240),\n",
      "      %encoder.blocks.4._project_conv.weight : Float(40, 240, 1, 1),\n",
      "      %encoder.blocks.4._bn2.weight : Float(40),\n",
      "      %encoder.blocks.4._bn2.bias : Float(40),\n",
      "      %encoder.blocks.4._bn2.running_mean : Float(40),\n",
      "      %encoder.blocks.4._bn2.running_var : Float(40),\n",
      "      %encoder.blocks.4._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.5._expand_conv.weight : Float(240, 40, 1, 1),\n",
      "      %encoder.blocks.5._bn0.weight : Float(240),\n",
      "      %encoder.blocks.5._bn0.bias : Float(240),\n",
      "      %encoder.blocks.5._bn0.running_mean : Float(240),\n",
      "      %encoder.blocks.5._bn0.running_var : Float(240),\n",
      "      %encoder.blocks.5._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.5._depthwise_conv.weight : Float(240, 1, 3, 3),\n",
      "      %encoder.blocks.5._bn1.weight : Float(240),\n",
      "      %encoder.blocks.5._bn1.bias : Float(240),\n",
      "      %encoder.blocks.5._bn1.running_mean : Float(240),\n",
      "      %encoder.blocks.5._bn1.running_var : Float(240),\n",
      "      %encoder.blocks.5._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.5._se_reduce.weight : Float(10, 240, 1, 1),\n",
      "      %encoder.blocks.5._se_reduce.bias : Float(10),\n",
      "      %encoder.blocks.5._se_expand.weight : Float(240, 10, 1, 1),\n",
      "      %encoder.blocks.5._se_expand.bias : Float(240),\n",
      "      %encoder.blocks.5._project_conv.weight : Float(80, 240, 1, 1),\n",
      "      %encoder.blocks.5._bn2.weight : Float(80),\n",
      "      %encoder.blocks.5._bn2.bias : Float(80),\n",
      "      %encoder.blocks.5._bn2.running_mean : Float(80),\n",
      "      %encoder.blocks.5._bn2.running_var : Float(80),\n",
      "      %encoder.blocks.5._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.6._expand_conv.weight : Float(480, 80, 1, 1),\n",
      "      %encoder.blocks.6._bn0.weight : Float(480),\n",
      "      %encoder.blocks.6._bn0.bias : Float(480),\n",
      "      %encoder.blocks.6._bn0.running_mean : Float(480),\n",
      "      %encoder.blocks.6._bn0.running_var : Float(480),\n",
      "      %encoder.blocks.6._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.6._depthwise_conv.weight : Float(480, 1, 3, 3),\n",
      "      %encoder.blocks.6._bn1.weight : Float(480),\n",
      "      %encoder.blocks.6._bn1.bias : Float(480),\n",
      "      %encoder.blocks.6._bn1.running_mean : Float(480),\n",
      "      %encoder.blocks.6._bn1.running_var : Float(480),\n",
      "      %encoder.blocks.6._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.6._se_reduce.weight : Float(20, 480, 1, 1),\n",
      "      %encoder.blocks.6._se_reduce.bias : Float(20),\n",
      "      %encoder.blocks.6._se_expand.weight : Float(480, 20, 1, 1),\n",
      "      %encoder.blocks.6._se_expand.bias : Float(480),\n",
      "      %encoder.blocks.6._project_conv.weight : Float(80, 480, 1, 1),\n",
      "      %encoder.blocks.6._bn2.weight : Float(80),\n",
      "      %encoder.blocks.6._bn2.bias : Float(80),\n",
      "      %encoder.blocks.6._bn2.running_mean : Float(80),\n",
      "      %encoder.blocks.6._bn2.running_var : Float(80),\n",
      "      %encoder.blocks.6._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.7._expand_conv.weight : Float(480, 80, 1, 1),\n",
      "      %encoder.blocks.7._bn0.weight : Float(480),\n",
      "      %encoder.blocks.7._bn0.bias : Float(480),\n",
      "      %encoder.blocks.7._bn0.running_mean : Float(480),\n",
      "      %encoder.blocks.7._bn0.running_var : Float(480),\n",
      "      %encoder.blocks.7._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.7._depthwise_conv.weight : Float(480, 1, 3, 3),\n",
      "      %encoder.blocks.7._bn1.weight : Float(480),\n",
      "      %encoder.blocks.7._bn1.bias : Float(480),\n",
      "      %encoder.blocks.7._bn1.running_mean : Float(480),\n",
      "      %encoder.blocks.7._bn1.running_var : Float(480),\n",
      "      %encoder.blocks.7._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.7._se_reduce.weight : Float(20, 480, 1, 1),\n",
      "      %encoder.blocks.7._se_reduce.bias : Float(20),\n",
      "      %encoder.blocks.7._se_expand.weight : Float(480, 20, 1, 1),\n",
      "      %encoder.blocks.7._se_expand.bias : Float(480),\n",
      "      %encoder.blocks.7._project_conv.weight : Float(80, 480, 1, 1),\n",
      "      %encoder.blocks.7._bn2.weight : Float(80),\n",
      "      %encoder.blocks.7._bn2.bias : Float(80),\n",
      "      %encoder.blocks.7._bn2.running_mean : Float(80),\n",
      "      %encoder.blocks.7._bn2.running_var : Float(80),\n",
      "      %encoder.blocks.7._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.8._expand_conv.weight : Float(480, 80, 1, 1),\n",
      "      %encoder.blocks.8._bn0.weight : Float(480),\n",
      "      %encoder.blocks.8._bn0.bias : Float(480),\n",
      "      %encoder.blocks.8._bn0.running_mean : Float(480),\n",
      "      %encoder.blocks.8._bn0.running_var : Float(480),\n",
      "      %encoder.blocks.8._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.8._depthwise_conv.weight : Float(480, 1, 5, 5),\n",
      "      %encoder.blocks.8._bn1.weight : Float(480),\n",
      "      %encoder.blocks.8._bn1.bias : Float(480),\n",
      "      %encoder.blocks.8._bn1.running_mean : Float(480),\n",
      "      %encoder.blocks.8._bn1.running_var : Float(480),\n",
      "      %encoder.blocks.8._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.8._se_reduce.weight : Float(20, 480, 1, 1),\n",
      "      %encoder.blocks.8._se_reduce.bias : Float(20),\n",
      "      %encoder.blocks.8._se_expand.weight : Float(480, 20, 1, 1),\n",
      "      %encoder.blocks.8._se_expand.bias : Float(480),\n",
      "      %encoder.blocks.8._project_conv.weight : Float(112, 480, 1, 1),\n",
      "      %encoder.blocks.8._bn2.weight : Float(112),\n",
      "      %encoder.blocks.8._bn2.bias : Float(112),\n",
      "      %encoder.blocks.8._bn2.running_mean : Float(112),\n",
      "      %encoder.blocks.8._bn2.running_var : Float(112),\n",
      "      %encoder.blocks.8._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.9._expand_conv.weight : Float(672, 112, 1, 1),\n",
      "      %encoder.blocks.9._bn0.weight : Float(672),\n",
      "      %encoder.blocks.9._bn0.bias : Float(672),\n",
      "      %encoder.blocks.9._bn0.running_mean : Float(672),\n",
      "      %encoder.blocks.9._bn0.running_var : Float(672),\n",
      "      %encoder.blocks.9._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.9._depthwise_conv.weight : Float(672, 1, 5, 5),\n",
      "      %encoder.blocks.9._bn1.weight : Float(672),\n",
      "      %encoder.blocks.9._bn1.bias : Float(672),\n",
      "      %encoder.blocks.9._bn1.running_mean : Float(672),\n",
      "      %encoder.blocks.9._bn1.running_var : Float(672),\n",
      "      %encoder.blocks.9._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.9._se_reduce.weight : Float(28, 672, 1, 1),\n",
      "      %encoder.blocks.9._se_reduce.bias : Float(28),\n",
      "      %encoder.blocks.9._se_expand.weight : Float(672, 28, 1, 1),\n",
      "      %encoder.blocks.9._se_expand.bias : Float(672),\n",
      "      %encoder.blocks.9._project_conv.weight : Float(112, 672, 1, 1),\n",
      "      %encoder.blocks.9._bn2.weight : Float(112),\n",
      "      %encoder.blocks.9._bn2.bias : Float(112),\n",
      "      %encoder.blocks.9._bn2.running_mean : Float(112),\n",
      "      %encoder.blocks.9._bn2.running_var : Float(112),\n",
      "      %encoder.blocks.9._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.10._expand_conv.weight : Float(672, 112, 1, 1),\n",
      "      %encoder.blocks.10._bn0.weight : Float(672),\n",
      "      %encoder.blocks.10._bn0.bias : Float(672),\n",
      "      %encoder.blocks.10._bn0.running_mean : Float(672),\n",
      "      %encoder.blocks.10._bn0.running_var : Float(672),\n",
      "      %encoder.blocks.10._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.10._depthwise_conv.weight : Float(672, 1, 5, 5),\n",
      "      %encoder.blocks.10._bn1.weight : Float(672),\n",
      "      %encoder.blocks.10._bn1.bias : Float(672),\n",
      "      %encoder.blocks.10._bn1.running_mean : Float(672),\n",
      "      %encoder.blocks.10._bn1.running_var : Float(672),\n",
      "      %encoder.blocks.10._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.10._se_reduce.weight : Float(28, 672, 1, 1),\n",
      "      %encoder.blocks.10._se_reduce.bias : Float(28),\n",
      "      %encoder.blocks.10._se_expand.weight : Float(672, 28, 1, 1),\n",
      "      %encoder.blocks.10._se_expand.bias : Float(672),\n",
      "      %encoder.blocks.10._project_conv.weight : Float(112, 672, 1, 1),\n",
      "      %encoder.blocks.10._bn2.weight : Float(112),\n",
      "      %encoder.blocks.10._bn2.bias : Float(112),\n",
      "      %encoder.blocks.10._bn2.running_mean : Float(112),\n",
      "      %encoder.blocks.10._bn2.running_var : Float(112),\n",
      "      %encoder.blocks.10._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.11._expand_conv.weight : Float(672, 112, 1, 1),\n",
      "      %encoder.blocks.11._bn0.weight : Float(672),\n",
      "      %encoder.blocks.11._bn0.bias : Float(672),\n",
      "      %encoder.blocks.11._bn0.running_mean : Float(672),\n",
      "      %encoder.blocks.11._bn0.running_var : Float(672),\n",
      "      %encoder.blocks.11._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.11._depthwise_conv.weight : Float(672, 1, 5, 5),\n",
      "      %encoder.blocks.11._bn1.weight : Float(672),\n",
      "      %encoder.blocks.11._bn1.bias : Float(672),\n",
      "      %encoder.blocks.11._bn1.running_mean : Float(672),\n",
      "      %encoder.blocks.11._bn1.running_var : Float(672),\n",
      "      %encoder.blocks.11._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.11._se_reduce.weight : Float(28, 672, 1, 1),\n",
      "      %encoder.blocks.11._se_reduce.bias : Float(28),\n",
      "      %encoder.blocks.11._se_expand.weight : Float(672, 28, 1, 1),\n",
      "      %encoder.blocks.11._se_expand.bias : Float(672),\n",
      "      %encoder.blocks.11._project_conv.weight : Float(192, 672, 1, 1),\n",
      "      %encoder.blocks.11._bn2.weight : Float(192),\n",
      "      %encoder.blocks.11._bn2.bias : Float(192),\n",
      "      %encoder.blocks.11._bn2.running_mean : Float(192),\n",
      "      %encoder.blocks.11._bn2.running_var : Float(192),\n",
      "      %encoder.blocks.11._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.12._expand_conv.weight : Float(1152, 192, 1, 1),\n",
      "      %encoder.blocks.12._bn0.weight : Float(1152),\n",
      "      %encoder.blocks.12._bn0.bias : Float(1152),\n",
      "      %encoder.blocks.12._bn0.running_mean : Float(1152),\n",
      "      %encoder.blocks.12._bn0.running_var : Float(1152),\n",
      "      %encoder.blocks.12._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.12._depthwise_conv.weight : Float(1152, 1, 5, 5),\n",
      "      %encoder.blocks.12._bn1.weight : Float(1152),\n",
      "      %encoder.blocks.12._bn1.bias : Float(1152),\n",
      "      %encoder.blocks.12._bn1.running_mean : Float(1152),\n",
      "      %encoder.blocks.12._bn1.running_var : Float(1152),\n",
      "      %encoder.blocks.12._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.12._se_reduce.weight : Float(48, 1152, 1, 1),\n",
      "      %encoder.blocks.12._se_reduce.bias : Float(48),\n",
      "      %encoder.blocks.12._se_expand.weight : Float(1152, 48, 1, 1),\n",
      "      %encoder.blocks.12._se_expand.bias : Float(1152),\n",
      "      %encoder.blocks.12._project_conv.weight : Float(192, 1152, 1, 1),\n",
      "      %encoder.blocks.12._bn2.weight : Float(192),\n",
      "      %encoder.blocks.12._bn2.bias : Float(192),\n",
      "      %encoder.blocks.12._bn2.running_mean : Float(192),\n",
      "      %encoder.blocks.12._bn2.running_var : Float(192),\n",
      "      %encoder.blocks.12._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.13._expand_conv.weight : Float(1152, 192, 1, 1),\n",
      "      %encoder.blocks.13._bn0.weight : Float(1152),\n",
      "      %encoder.blocks.13._bn0.bias : Float(1152),\n",
      "      %encoder.blocks.13._bn0.running_mean : Float(1152),\n",
      "      %encoder.blocks.13._bn0.running_var : Float(1152),\n",
      "      %encoder.blocks.13._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.13._depthwise_conv.weight : Float(1152, 1, 5, 5),\n",
      "      %encoder.blocks.13._bn1.weight : Float(1152),\n",
      "      %encoder.blocks.13._bn1.bias : Float(1152),\n",
      "      %encoder.blocks.13._bn1.running_mean : Float(1152),\n",
      "      %encoder.blocks.13._bn1.running_var : Float(1152),\n",
      "      %encoder.blocks.13._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.13._se_reduce.weight : Float(48, 1152, 1, 1),\n",
      "      %encoder.blocks.13._se_reduce.bias : Float(48),\n",
      "      %encoder.blocks.13._se_expand.weight : Float(1152, 48, 1, 1),\n",
      "      %encoder.blocks.13._se_expand.bias : Float(1152),\n",
      "      %encoder.blocks.13._project_conv.weight : Float(192, 1152, 1, 1),\n",
      "      %encoder.blocks.13._bn2.weight : Float(192),\n",
      "      %encoder.blocks.13._bn2.bias : Float(192),\n",
      "      %encoder.blocks.13._bn2.running_mean : Float(192),\n",
      "      %encoder.blocks.13._bn2.running_var : Float(192),\n",
      "      %encoder.blocks.13._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.14._expand_conv.weight : Float(1152, 192, 1, 1),\n",
      "      %encoder.blocks.14._bn0.weight : Float(1152),\n",
      "      %encoder.blocks.14._bn0.bias : Float(1152),\n",
      "      %encoder.blocks.14._bn0.running_mean : Float(1152),\n",
      "      %encoder.blocks.14._bn0.running_var : Float(1152),\n",
      "      %encoder.blocks.14._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.14._depthwise_conv.weight : Float(1152, 1, 5, 5),\n",
      "      %encoder.blocks.14._bn1.weight : Float(1152),\n",
      "      %encoder.blocks.14._bn1.bias : Float(1152),\n",
      "      %encoder.blocks.14._bn1.running_mean : Float(1152),\n",
      "      %encoder.blocks.14._bn1.running_var : Float(1152),\n",
      "      %encoder.blocks.14._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.14._se_reduce.weight : Float(48, 1152, 1, 1),\n",
      "      %encoder.blocks.14._se_reduce.bias : Float(48),\n",
      "      %encoder.blocks.14._se_expand.weight : Float(1152, 48, 1, 1),\n",
      "      %encoder.blocks.14._se_expand.bias : Float(1152),\n",
      "      %encoder.blocks.14._project_conv.weight : Float(192, 1152, 1, 1),\n",
      "      %encoder.blocks.14._bn2.weight : Float(192),\n",
      "      %encoder.blocks.14._bn2.bias : Float(192),\n",
      "      %encoder.blocks.14._bn2.running_mean : Float(192),\n",
      "      %encoder.blocks.14._bn2.running_var : Float(192),\n",
      "      %encoder.blocks.14._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.15._expand_conv.weight : Float(1152, 192, 1, 1),\n",
      "      %encoder.blocks.15._bn0.weight : Float(1152),\n",
      "      %encoder.blocks.15._bn0.bias : Float(1152),\n",
      "      %encoder.blocks.15._bn0.running_mean : Float(1152),\n",
      "      %encoder.blocks.15._bn0.running_var : Float(1152),\n",
      "      %encoder.blocks.15._bn0.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.15._depthwise_conv.weight : Float(1152, 1, 3, 3),\n",
      "      %encoder.blocks.15._bn1.weight : Float(1152),\n",
      "      %encoder.blocks.15._bn1.bias : Float(1152),\n",
      "      %encoder.blocks.15._bn1.running_mean : Float(1152),\n",
      "      %encoder.blocks.15._bn1.running_var : Float(1152),\n",
      "      %encoder.blocks.15._bn1.num_batches_tracked : Long(),\n",
      "      %encoder.blocks.15._se_reduce.weight : Float(48, 1152, 1, 1),\n",
      "      %encoder.blocks.15._se_reduce.bias : Float(48),\n",
      "      %encoder.blocks.15._se_expand.weight : Float(1152, 48, 1, 1),\n",
      "      %encoder.blocks.15._se_expand.bias : Float(1152),\n",
      "      %encoder.blocks.15._project_conv.weight : Float(320, 1152, 1, 1),\n",
      "      %encoder.blocks.15._bn2.weight : Float(320),\n",
      "      %encoder.blocks.15._bn2.bias : Float(320),\n",
      "      %encoder.blocks.15._bn2.running_mean : Float(320),\n",
      "      %encoder.blocks.15._bn2.running_var : Float(320),\n",
      "      %encoder.blocks.15._bn2.num_batches_tracked : Long(),\n",
      "      %encoder.head_conv.weight : Float(1280, 320, 1, 1),\n",
      "      %encoder.head_batch_norm.weight : Float(1280),\n",
      "      %encoder.head_batch_norm.bias : Float(1280),\n",
      "      %encoder.head_batch_norm.running_mean : Float(1280),\n",
      "      %encoder.head_batch_norm.running_var : Float(1280),\n",
      "      %encoder.head_batch_norm.num_batches_tracked : Long(),\n",
      "      %up_conv1.conv.weight : Float(512, 1280, 2, 2),\n",
      "      %up_conv1.conv.bias : Float(512),\n",
      "      %double_conv1.0.weight : Float(512, 592, 3, 3),\n",
      "      %double_conv1.0.bias : Float(512),\n",
      "      %double_conv1.1.weight : Float(512),\n",
      "      %double_conv1.1.bias : Float(512),\n",
      "      %double_conv1.1.running_mean : Float(512),\n",
      "      %double_conv1.1.running_var : Float(512),\n",
      "      %double_conv1.1.num_batches_tracked : Long(),\n",
      "      %double_conv1.3.weight : Float(512, 512, 3, 3),\n",
      "      %double_conv1.3.bias : Float(512),\n",
      "      %double_conv1.4.weight : Float(512),\n",
      "      %double_conv1.4.bias : Float(512),\n",
      "      %double_conv1.4.running_mean : Float(512),\n",
      "      %double_conv1.4.running_var : Float(512),\n",
      "      %double_conv1.4.num_batches_tracked : Long(),\n",
      "      %up_conv2.conv.weight : Float(256, 512, 2, 2),\n",
      "      %up_conv2.conv.bias : Float(256),\n",
      "      %double_conv2.0.weight : Float(256, 296, 3, 3),\n",
      "      %double_conv2.0.bias : Float(256),\n",
      "      %double_conv2.1.weight : Float(256),\n",
      "      %double_conv2.1.bias : Float(256),\n",
      "      %double_conv2.1.running_mean : Float(256),\n",
      "      %double_conv2.1.running_var : Float(256),\n",
      "      %double_conv2.1.num_batches_tracked : Long(),\n",
      "      %double_conv2.3.weight : Float(256, 256, 3, 3),\n",
      "      %double_conv2.3.bias : Float(256),\n",
      "      %double_conv2.4.weight : Float(256),\n",
      "      %double_conv2.4.bias : Float(256),\n",
      "      %double_conv2.4.running_mean : Float(256),\n",
      "      %double_conv2.4.running_var : Float(256),\n",
      "      %double_conv2.4.num_batches_tracked : Long(),\n",
      "      %up_conv3.conv.weight : Float(128, 256, 2, 2),\n",
      "      %up_conv3.conv.bias : Float(128),\n",
      "      %double_conv3.0.weight : Float(128, 152, 3, 3),\n",
      "      %double_conv3.0.bias : Float(128),\n",
      "      %double_conv3.1.weight : Float(128),\n",
      "      %double_conv3.1.bias : Float(128),\n",
      "      %double_conv3.1.running_mean : Float(128),\n",
      "      %double_conv3.1.running_var : Float(128),\n",
      "      %double_conv3.1.num_batches_tracked : Long(),\n",
      "      %double_conv3.3.weight : Float(128, 128, 3, 3),\n",
      "      %double_conv3.3.bias : Float(128),\n",
      "      %double_conv3.4.weight : Float(128),\n",
      "      %double_conv3.4.bias : Float(128),\n",
      "      %double_conv3.4.running_mean : Float(128),\n",
      "      %double_conv3.4.running_var : Float(128),\n",
      "      %double_conv3.4.num_batches_tracked : Long(),\n",
      "      %up_conv4.conv.weight : Float(64, 128, 2, 2),\n",
      "      %up_conv4.conv.bias : Float(64),\n",
      "      %double_conv4.0.weight : Float(64, 80, 3, 3),\n",
      "      %double_conv4.0.bias : Float(64),\n",
      "      %double_conv4.1.weight : Float(64),\n",
      "      %double_conv4.1.bias : Float(64),\n",
      "      %double_conv4.1.running_mean : Float(64),\n",
      "      %double_conv4.1.running_var : Float(64),\n",
      "      %double_conv4.1.num_batches_tracked : Long(),\n",
      "      %double_conv4.3.weight : Float(64, 64, 3, 3),\n",
      "      %double_conv4.3.bias : Float(64),\n",
      "      %double_conv4.4.weight : Float(64),\n",
      "      %double_conv4.4.bias : Float(64),\n",
      "      %double_conv4.4.running_mean : Float(64),\n",
      "      %double_conv4.4.running_var : Float(64),\n",
      "      %double_conv4.4.num_batches_tracked : Long(),\n",
      "      %up_conv_input.conv.weight : Float(32, 64, 2, 2),\n",
      "      %up_conv_input.conv.bias : Float(32),\n",
      "      %double_conv_input.0.weight : Float(32, 34, 3, 3),\n",
      "      %double_conv_input.0.bias : Float(32),\n",
      "      %double_conv_input.1.weight : Float(32),\n",
      "      %double_conv_input.1.bias : Float(32),\n",
      "      %double_conv_input.1.running_mean : Float(32),\n",
      "      %double_conv_input.1.running_var : Float(32),\n",
      "      %double_conv_input.1.num_batches_tracked : Long(),\n",
      "      %double_conv_input.3.weight : Float(32, 32, 3, 3),\n",
      "      %double_conv_input.3.bias : Float(32),\n",
      "      %double_conv_input.4.weight : Float(32),\n",
      "      %double_conv_input.4.bias : Float(32),\n",
      "      %double_conv_input.4.running_mean : Float(32),\n",
      "      %double_conv_input.4.running_var : Float(32),\n",
      "      %double_conv_input.4.num_batches_tracked : Long(),\n",
      "      %final_conv.weight : Float(3, 32, 1, 1),\n",
      "      %final_conv.bias : Float(3)):\n",
      "  %441 : Float(1, 2, 259, 65) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 0, 0, 0, 1, 1], value=0](%input), scope: EfficientUnet/Encoder[encoder]/Conv2dSamePadding[stem_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %442 : Float(1, 32, 129, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%441, %encoder.stem_conv.weight), scope: EfficientUnet/Encoder[encoder]/Conv2dSamePadding[stem_conv] # ../efficientunet/layers.py:48:0\n",
      "  %443 : Float(1, 32, 129, 32) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%442, %encoder.stem_batch_norm.weight, %encoder.stem_batch_norm.bias, %encoder.stem_batch_norm.running_mean, %encoder.stem_batch_norm.running_var), scope: EfficientUnet/Encoder[encoder]/BatchNorm2d[stem_batch_norm] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %444 : Float(1, 32, 129, 32) = onnx::Sigmoid(%443), scope: EfficientUnet/Encoder[encoder]/Swish[stem_swish] # ../efficientunet/layers.py:14:0\n",
      "  %445 : Float(1, 32, 129, 32) = onnx::Mul(%443, %444), scope: EfficientUnet/Encoder[encoder]/Swish[stem_swish] # ../efficientunet/layers.py:14:0\n",
      "  %446 : Float(1, 32, 131, 34) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 1, 0, 0, 1, 1], value=0](%445), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %447 : Float(1, 32, 129, 32) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%446, %encoder.blocks.0._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %448 : Float(1, 32, 129, 32) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%447, %encoder.blocks.0._bn1.weight, %encoder.blocks.0._bn1.bias, %encoder.blocks.0._bn1.running_mean, %encoder.blocks.0._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %449 : Float(1, 32, 129, 32) = onnx::Sigmoid(%448), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %450 : Float(1, 32, 129, 32) = onnx::Mul(%448, %449), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %451 : Float(1, 32, 1, 1) = onnx::GlobalAveragePool(%450), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %452 : Float(1, 8, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%451, %encoder.blocks.0._se_reduce.weight, %encoder.blocks.0._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %453 : Float(1, 8, 1, 1) = onnx::Sigmoid(%452), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %454 : Float(1, 8, 1, 1) = onnx::Mul(%452, %453), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %455 : Float(1, 32, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%454, %encoder.blocks.0._se_expand.weight, %encoder.blocks.0._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %456 : Float(1, 32, 1, 1) = onnx::Sigmoid(%455), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %457 : Float(1, 32, 129, 32) = onnx::Mul(%456, %450), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %458 : Float(1, 16, 129, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%457, %encoder.blocks.0._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %459 : Float(1, 16, 129, 32) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%458, %encoder.blocks.0._bn2.weight, %encoder.blocks.0._bn2.bias, %encoder.blocks.0._bn2.running_mean, %encoder.blocks.0._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %460 : Float(1, 96, 129, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%459, %encoder.blocks.1._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %461 : Float(1, 96, 129, 32) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%460, %encoder.blocks.1._bn0.weight, %encoder.blocks.1._bn0.bias, %encoder.blocks.1._bn0.running_mean, %encoder.blocks.1._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %462 : Float(1, 96, 129, 32) = onnx::Sigmoid(%461), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %463 : Float(1, 96, 129, 32) = onnx::Mul(%461, %462), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %464 : Float(1, 96, 131, 33) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 0, 0, 0, 1, 1], value=0](%463), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %465 : Float(1, 96, 65, 16) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%464, %encoder.blocks.1._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %466 : Float(1, 96, 65, 16) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%465, %encoder.blocks.1._bn1.weight, %encoder.blocks.1._bn1.bias, %encoder.blocks.1._bn1.running_mean, %encoder.blocks.1._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %467 : Float(1, 96, 65, 16) = onnx::Sigmoid(%466), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %468 : Float(1, 96, 65, 16) = onnx::Mul(%466, %467), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %469 : Float(1, 96, 1, 1) = onnx::GlobalAveragePool(%468), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %470 : Float(1, 4, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%469, %encoder.blocks.1._se_reduce.weight, %encoder.blocks.1._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %471 : Float(1, 4, 1, 1) = onnx::Sigmoid(%470), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %472 : Float(1, 4, 1, 1) = onnx::Mul(%470, %471), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %473 : Float(1, 96, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%472, %encoder.blocks.1._se_expand.weight, %encoder.blocks.1._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %474 : Float(1, 96, 1, 1) = onnx::Sigmoid(%473), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %475 : Float(1, 96, 65, 16) = onnx::Mul(%474, %468), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %476 : Float(1, 24, 65, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%475, %encoder.blocks.1._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %477 : Float(1, 24, 65, 16) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%476, %encoder.blocks.1._bn2.weight, %encoder.blocks.1._bn2.bias, %encoder.blocks.1._bn2.running_mean, %encoder.blocks.1._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %478 : Float(1, 144, 65, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%477, %encoder.blocks.2._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %479 : Float(1, 144, 65, 16) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%478, %encoder.blocks.2._bn0.weight, %encoder.blocks.2._bn0.bias, %encoder.blocks.2._bn0.running_mean, %encoder.blocks.2._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %480 : Float(1, 144, 65, 16) = onnx::Sigmoid(%479), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %481 : Float(1, 144, 65, 16) = onnx::Mul(%479, %480), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %482 : Float(1, 144, 67, 18) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 1, 0, 0, 1, 1], value=0](%481), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %483 : Float(1, 144, 65, 16) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%482, %encoder.blocks.2._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %484 : Float(1, 144, 65, 16) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%483, %encoder.blocks.2._bn1.weight, %encoder.blocks.2._bn1.bias, %encoder.blocks.2._bn1.running_mean, %encoder.blocks.2._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %485 : Float(1, 144, 65, 16) = onnx::Sigmoid(%484), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %486 : Float(1, 144, 65, 16) = onnx::Mul(%484, %485), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %487 : Float(1, 144, 1, 1) = onnx::GlobalAveragePool(%486), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %488 : Float(1, 6, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%487, %encoder.blocks.2._se_reduce.weight, %encoder.blocks.2._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %489 : Float(1, 6, 1, 1) = onnx::Sigmoid(%488), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %490 : Float(1, 6, 1, 1) = onnx::Mul(%488, %489), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %491 : Float(1, 144, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%490, %encoder.blocks.2._se_expand.weight, %encoder.blocks.2._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %492 : Float(1, 144, 1, 1) = onnx::Sigmoid(%491), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %493 : Float(1, 144, 65, 16) = onnx::Mul(%492, %486), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %494 : Float(1, 24, 65, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%493, %encoder.blocks.2._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %495 : Float(1, 24, 65, 16) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%494, %encoder.blocks.2._bn2.weight, %encoder.blocks.2._bn2.bias, %encoder.blocks.2._bn2.running_mean, %encoder.blocks.2._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %496 : Float(1, 24, 65, 16) = onnx::Add(%495, %477), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %497 : Float(1, 144, 65, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%496, %encoder.blocks.3._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %498 : Float(1, 144, 65, 16) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%497, %encoder.blocks.3._bn0.weight, %encoder.blocks.3._bn0.bias, %encoder.blocks.3._bn0.running_mean, %encoder.blocks.3._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %499 : Float(1, 144, 65, 16) = onnx::Sigmoid(%498), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %500 : Float(1, 144, 65, 16) = onnx::Mul(%498, %499), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %501 : Float(1, 144, 69, 19) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 1, 0, 0, 2, 2], value=0](%500), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %502 : Float(1, 144, 33, 8) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[2, 2]](%501, %encoder.blocks.3._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %503 : Float(1, 144, 33, 8) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%502, %encoder.blocks.3._bn1.weight, %encoder.blocks.3._bn1.bias, %encoder.blocks.3._bn1.running_mean, %encoder.blocks.3._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %504 : Float(1, 144, 33, 8) = onnx::Sigmoid(%503), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %505 : Float(1, 144, 33, 8) = onnx::Mul(%503, %504), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %506 : Float(1, 144, 1, 1) = onnx::GlobalAveragePool(%505), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %507 : Float(1, 6, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%506, %encoder.blocks.3._se_reduce.weight, %encoder.blocks.3._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %508 : Float(1, 6, 1, 1) = onnx::Sigmoid(%507), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %509 : Float(1, 6, 1, 1) = onnx::Mul(%507, %508), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %510 : Float(1, 144, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%509, %encoder.blocks.3._se_expand.weight, %encoder.blocks.3._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %511 : Float(1, 144, 1, 1) = onnx::Sigmoid(%510), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %512 : Float(1, 144, 33, 8) = onnx::Mul(%511, %505), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %513 : Float(1, 40, 33, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%512, %encoder.blocks.3._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %514 : Float(1, 40, 33, 8) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%513, %encoder.blocks.3._bn2.weight, %encoder.blocks.3._bn2.bias, %encoder.blocks.3._bn2.running_mean, %encoder.blocks.3._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %515 : Float(1, 240, 33, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%514, %encoder.blocks.4._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %516 : Float(1, 240, 33, 8) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%515, %encoder.blocks.4._bn0.weight, %encoder.blocks.4._bn0.bias, %encoder.blocks.4._bn0.running_mean, %encoder.blocks.4._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %517 : Float(1, 240, 33, 8) = onnx::Sigmoid(%516), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %518 : Float(1, 240, 33, 8) = onnx::Mul(%516, %517), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %519 : Float(1, 240, 37, 12) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%518), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %520 : Float(1, 240, 33, 8) = onnx::Conv[dilations=[1, 1], group=240, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%519, %encoder.blocks.4._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %521 : Float(1, 240, 33, 8) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%520, %encoder.blocks.4._bn1.weight, %encoder.blocks.4._bn1.bias, %encoder.blocks.4._bn1.running_mean, %encoder.blocks.4._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %522 : Float(1, 240, 33, 8) = onnx::Sigmoid(%521), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %523 : Float(1, 240, 33, 8) = onnx::Mul(%521, %522), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %524 : Float(1, 240, 1, 1) = onnx::GlobalAveragePool(%523), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %525 : Float(1, 10, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%524, %encoder.blocks.4._se_reduce.weight, %encoder.blocks.4._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %526 : Float(1, 10, 1, 1) = onnx::Sigmoid(%525), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %527 : Float(1, 10, 1, 1) = onnx::Mul(%525, %526), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %528 : Float(1, 240, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%527, %encoder.blocks.4._se_expand.weight, %encoder.blocks.4._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %529 : Float(1, 240, 1, 1) = onnx::Sigmoid(%528), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %530 : Float(1, 240, 33, 8) = onnx::Mul(%529, %523), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %531 : Float(1, 40, 33, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%530, %encoder.blocks.4._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %532 : Float(1, 40, 33, 8) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%531, %encoder.blocks.4._bn2.weight, %encoder.blocks.4._bn2.bias, %encoder.blocks.4._bn2.running_mean, %encoder.blocks.4._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %533 : Float(1, 40, 33, 8) = onnx::Add(%532, %514), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %534 : Float(1, 240, 33, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%533, %encoder.blocks.5._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %535 : Float(1, 240, 33, 8) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%534, %encoder.blocks.5._bn0.weight, %encoder.blocks.5._bn0.bias, %encoder.blocks.5._bn0.running_mean, %encoder.blocks.5._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %536 : Float(1, 240, 33, 8) = onnx::Sigmoid(%535), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %537 : Float(1, 240, 33, 8) = onnx::Mul(%535, %536), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %538 : Float(1, 240, 35, 9) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 0, 0, 0, 1, 1], value=0](%537), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %539 : Float(1, 240, 17, 4) = onnx::Conv[dilations=[1, 1], group=240, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%538, %encoder.blocks.5._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %540 : Float(1, 240, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%539, %encoder.blocks.5._bn1.weight, %encoder.blocks.5._bn1.bias, %encoder.blocks.5._bn1.running_mean, %encoder.blocks.5._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %541 : Float(1, 240, 17, 4) = onnx::Sigmoid(%540), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %542 : Float(1, 240, 17, 4) = onnx::Mul(%540, %541), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %543 : Float(1, 240, 1, 1) = onnx::GlobalAveragePool(%542), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %544 : Float(1, 10, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%543, %encoder.blocks.5._se_reduce.weight, %encoder.blocks.5._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %545 : Float(1, 10, 1, 1) = onnx::Sigmoid(%544), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %546 : Float(1, 10, 1, 1) = onnx::Mul(%544, %545), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %547 : Float(1, 240, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%546, %encoder.blocks.5._se_expand.weight, %encoder.blocks.5._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %548 : Float(1, 240, 1, 1) = onnx::Sigmoid(%547), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %549 : Float(1, 240, 17, 4) = onnx::Mul(%548, %542), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %550 : Float(1, 80, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%549, %encoder.blocks.5._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %551 : Float(1, 80, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%550, %encoder.blocks.5._bn2.weight, %encoder.blocks.5._bn2.bias, %encoder.blocks.5._bn2.running_mean, %encoder.blocks.5._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %552 : Float(1, 480, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%551, %encoder.blocks.6._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %553 : Float(1, 480, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%552, %encoder.blocks.6._bn0.weight, %encoder.blocks.6._bn0.bias, %encoder.blocks.6._bn0.running_mean, %encoder.blocks.6._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %554 : Float(1, 480, 17, 4) = onnx::Sigmoid(%553), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %555 : Float(1, 480, 17, 4) = onnx::Mul(%553, %554), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %556 : Float(1, 480, 19, 6) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 1, 0, 0, 1, 1], value=0](%555), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %557 : Float(1, 480, 17, 4) = onnx::Conv[dilations=[1, 1], group=480, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%556, %encoder.blocks.6._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %558 : Float(1, 480, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%557, %encoder.blocks.6._bn1.weight, %encoder.blocks.6._bn1.bias, %encoder.blocks.6._bn1.running_mean, %encoder.blocks.6._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %559 : Float(1, 480, 17, 4) = onnx::Sigmoid(%558), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %560 : Float(1, 480, 17, 4) = onnx::Mul(%558, %559), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %561 : Float(1, 480, 1, 1) = onnx::GlobalAveragePool(%560), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %562 : Float(1, 20, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%561, %encoder.blocks.6._se_reduce.weight, %encoder.blocks.6._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %563 : Float(1, 20, 1, 1) = onnx::Sigmoid(%562), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %564 : Float(1, 20, 1, 1) = onnx::Mul(%562, %563), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %565 : Float(1, 480, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%564, %encoder.blocks.6._se_expand.weight, %encoder.blocks.6._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %566 : Float(1, 480, 1, 1) = onnx::Sigmoid(%565), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %567 : Float(1, 480, 17, 4) = onnx::Mul(%566, %560), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %568 : Float(1, 80, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%567, %encoder.blocks.6._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %569 : Float(1, 80, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%568, %encoder.blocks.6._bn2.weight, %encoder.blocks.6._bn2.bias, %encoder.blocks.6._bn2.running_mean, %encoder.blocks.6._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %570 : Float(1, 80, 17, 4) = onnx::Add(%569, %551), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %571 : Float(1, 480, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%570, %encoder.blocks.7._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %572 : Float(1, 480, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%571, %encoder.blocks.7._bn0.weight, %encoder.blocks.7._bn0.bias, %encoder.blocks.7._bn0.running_mean, %encoder.blocks.7._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %573 : Float(1, 480, 17, 4) = onnx::Sigmoid(%572), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %574 : Float(1, 480, 17, 4) = onnx::Mul(%572, %573), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %575 : Float(1, 480, 19, 6) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 1, 0, 0, 1, 1], value=0](%574), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %576 : Float(1, 480, 17, 4) = onnx::Conv[dilations=[1, 1], group=480, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%575, %encoder.blocks.7._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %577 : Float(1, 480, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%576, %encoder.blocks.7._bn1.weight, %encoder.blocks.7._bn1.bias, %encoder.blocks.7._bn1.running_mean, %encoder.blocks.7._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %578 : Float(1, 480, 17, 4) = onnx::Sigmoid(%577), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %579 : Float(1, 480, 17, 4) = onnx::Mul(%577, %578), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %580 : Float(1, 480, 1, 1) = onnx::GlobalAveragePool(%579), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %581 : Float(1, 20, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%580, %encoder.blocks.7._se_reduce.weight, %encoder.blocks.7._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %582 : Float(1, 20, 1, 1) = onnx::Sigmoid(%581), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %583 : Float(1, 20, 1, 1) = onnx::Mul(%581, %582), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %584 : Float(1, 480, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%583, %encoder.blocks.7._se_expand.weight, %encoder.blocks.7._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %585 : Float(1, 480, 1, 1) = onnx::Sigmoid(%584), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %586 : Float(1, 480, 17, 4) = onnx::Mul(%585, %579), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %587 : Float(1, 80, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%586, %encoder.blocks.7._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %588 : Float(1, 80, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%587, %encoder.blocks.7._bn2.weight, %encoder.blocks.7._bn2.bias, %encoder.blocks.7._bn2.running_mean, %encoder.blocks.7._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %589 : Float(1, 80, 17, 4) = onnx::Add(%588, %570), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %590 : Float(1, 480, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%589, %encoder.blocks.8._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %591 : Float(1, 480, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%590, %encoder.blocks.8._bn0.weight, %encoder.blocks.8._bn0.bias, %encoder.blocks.8._bn0.running_mean, %encoder.blocks.8._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %592 : Float(1, 480, 17, 4) = onnx::Sigmoid(%591), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %593 : Float(1, 480, 17, 4) = onnx::Mul(%591, %592), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %594 : Float(1, 480, 21, 8) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%593), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %595 : Float(1, 480, 17, 4) = onnx::Conv[dilations=[1, 1], group=480, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%594, %encoder.blocks.8._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %596 : Float(1, 480, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%595, %encoder.blocks.8._bn1.weight, %encoder.blocks.8._bn1.bias, %encoder.blocks.8._bn1.running_mean, %encoder.blocks.8._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %597 : Float(1, 480, 17, 4) = onnx::Sigmoid(%596), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %598 : Float(1, 480, 17, 4) = onnx::Mul(%596, %597), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %599 : Float(1, 480, 1, 1) = onnx::GlobalAveragePool(%598), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %600 : Float(1, 20, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%599, %encoder.blocks.8._se_reduce.weight, %encoder.blocks.8._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %601 : Float(1, 20, 1, 1) = onnx::Sigmoid(%600), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %602 : Float(1, 20, 1, 1) = onnx::Mul(%600, %601), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %603 : Float(1, 480, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%602, %encoder.blocks.8._se_expand.weight, %encoder.blocks.8._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %604 : Float(1, 480, 1, 1) = onnx::Sigmoid(%603), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %605 : Float(1, 480, 17, 4) = onnx::Mul(%604, %598), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %606 : Float(1, 112, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%605, %encoder.blocks.8._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %607 : Float(1, 112, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%606, %encoder.blocks.8._bn2.weight, %encoder.blocks.8._bn2.bias, %encoder.blocks.8._bn2.running_mean, %encoder.blocks.8._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %608 : Float(1, 672, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%607, %encoder.blocks.9._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %609 : Float(1, 672, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%608, %encoder.blocks.9._bn0.weight, %encoder.blocks.9._bn0.bias, %encoder.blocks.9._bn0.running_mean, %encoder.blocks.9._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %610 : Float(1, 672, 17, 4) = onnx::Sigmoid(%609), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %611 : Float(1, 672, 17, 4) = onnx::Mul(%609, %610), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %612 : Float(1, 672, 21, 8) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%611), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %613 : Float(1, 672, 17, 4) = onnx::Conv[dilations=[1, 1], group=672, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%612, %encoder.blocks.9._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %614 : Float(1, 672, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%613, %encoder.blocks.9._bn1.weight, %encoder.blocks.9._bn1.bias, %encoder.blocks.9._bn1.running_mean, %encoder.blocks.9._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %615 : Float(1, 672, 17, 4) = onnx::Sigmoid(%614), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %616 : Float(1, 672, 17, 4) = onnx::Mul(%614, %615), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %617 : Float(1, 672, 1, 1) = onnx::GlobalAveragePool(%616), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %618 : Float(1, 28, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%617, %encoder.blocks.9._se_reduce.weight, %encoder.blocks.9._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %619 : Float(1, 28, 1, 1) = onnx::Sigmoid(%618), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %620 : Float(1, 28, 1, 1) = onnx::Mul(%618, %619), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %621 : Float(1, 672, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%620, %encoder.blocks.9._se_expand.weight, %encoder.blocks.9._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %622 : Float(1, 672, 1, 1) = onnx::Sigmoid(%621), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %623 : Float(1, 672, 17, 4) = onnx::Mul(%622, %616), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %624 : Float(1, 112, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%623, %encoder.blocks.9._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %625 : Float(1, 112, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%624, %encoder.blocks.9._bn2.weight, %encoder.blocks.9._bn2.bias, %encoder.blocks.9._bn2.running_mean, %encoder.blocks.9._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %626 : Float(1, 112, 17, 4) = onnx::Add(%625, %607), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %627 : Float(1, 672, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%626, %encoder.blocks.10._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %628 : Float(1, 672, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%627, %encoder.blocks.10._bn0.weight, %encoder.blocks.10._bn0.bias, %encoder.blocks.10._bn0.running_mean, %encoder.blocks.10._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %629 : Float(1, 672, 17, 4) = onnx::Sigmoid(%628), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %630 : Float(1, 672, 17, 4) = onnx::Mul(%628, %629), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %631 : Float(1, 672, 21, 8) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%630), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %632 : Float(1, 672, 17, 4) = onnx::Conv[dilations=[1, 1], group=672, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%631, %encoder.blocks.10._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %633 : Float(1, 672, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%632, %encoder.blocks.10._bn1.weight, %encoder.blocks.10._bn1.bias, %encoder.blocks.10._bn1.running_mean, %encoder.blocks.10._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %634 : Float(1, 672, 17, 4) = onnx::Sigmoid(%633), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %635 : Float(1, 672, 17, 4) = onnx::Mul(%633, %634), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %636 : Float(1, 672, 1, 1) = onnx::GlobalAveragePool(%635), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %637 : Float(1, 28, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%636, %encoder.blocks.10._se_reduce.weight, %encoder.blocks.10._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %638 : Float(1, 28, 1, 1) = onnx::Sigmoid(%637), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %639 : Float(1, 28, 1, 1) = onnx::Mul(%637, %638), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %640 : Float(1, 672, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%639, %encoder.blocks.10._se_expand.weight, %encoder.blocks.10._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %641 : Float(1, 672, 1, 1) = onnx::Sigmoid(%640), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %642 : Float(1, 672, 17, 4) = onnx::Mul(%641, %635), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %643 : Float(1, 112, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%642, %encoder.blocks.10._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %644 : Float(1, 112, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%643, %encoder.blocks.10._bn2.weight, %encoder.blocks.10._bn2.bias, %encoder.blocks.10._bn2.running_mean, %encoder.blocks.10._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %645 : Float(1, 112, 17, 4) = onnx::Add(%644, %626), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %646 : Float(1, 672, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%645, %encoder.blocks.11._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %647 : Float(1, 672, 17, 4) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%646, %encoder.blocks.11._bn0.weight, %encoder.blocks.11._bn0.bias, %encoder.blocks.11._bn0.running_mean, %encoder.blocks.11._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %648 : Float(1, 672, 17, 4) = onnx::Sigmoid(%647), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %649 : Float(1, 672, 17, 4) = onnx::Mul(%647, %648), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %650 : Float(1, 672, 21, 7) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 1, 0, 0, 2, 2], value=0](%649), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %651 : Float(1, 672, 9, 2) = onnx::Conv[dilations=[1, 1], group=672, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[2, 2]](%650, %encoder.blocks.11._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %652 : Float(1, 672, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%651, %encoder.blocks.11._bn1.weight, %encoder.blocks.11._bn1.bias, %encoder.blocks.11._bn1.running_mean, %encoder.blocks.11._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %653 : Float(1, 672, 9, 2) = onnx::Sigmoid(%652), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %654 : Float(1, 672, 9, 2) = onnx::Mul(%652, %653), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %655 : Float(1, 672, 1, 1) = onnx::GlobalAveragePool(%654), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %656 : Float(1, 28, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%655, %encoder.blocks.11._se_reduce.weight, %encoder.blocks.11._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %657 : Float(1, 28, 1, 1) = onnx::Sigmoid(%656), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %658 : Float(1, 28, 1, 1) = onnx::Mul(%656, %657), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %659 : Float(1, 672, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%658, %encoder.blocks.11._se_expand.weight, %encoder.blocks.11._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %660 : Float(1, 672, 1, 1) = onnx::Sigmoid(%659), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %661 : Float(1, 672, 9, 2) = onnx::Mul(%660, %654), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %662 : Float(1, 192, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%661, %encoder.blocks.11._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %663 : Float(1, 192, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%662, %encoder.blocks.11._bn2.weight, %encoder.blocks.11._bn2.bias, %encoder.blocks.11._bn2.running_mean, %encoder.blocks.11._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %664 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%663, %encoder.blocks.12._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %665 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%664, %encoder.blocks.12._bn0.weight, %encoder.blocks.12._bn0.bias, %encoder.blocks.12._bn0.running_mean, %encoder.blocks.12._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %666 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%665), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %667 : Float(1, 1152, 9, 2) = onnx::Mul(%665, %666), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %668 : Float(1, 1152, 13, 6) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%667), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %669 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1152, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%668, %encoder.blocks.12._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %670 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%669, %encoder.blocks.12._bn1.weight, %encoder.blocks.12._bn1.bias, %encoder.blocks.12._bn1.running_mean, %encoder.blocks.12._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %671 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%670), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %672 : Float(1, 1152, 9, 2) = onnx::Mul(%670, %671), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %673 : Float(1, 1152, 1, 1) = onnx::GlobalAveragePool(%672), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %674 : Float(1, 48, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%673, %encoder.blocks.12._se_reduce.weight, %encoder.blocks.12._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %675 : Float(1, 48, 1, 1) = onnx::Sigmoid(%674), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %676 : Float(1, 48, 1, 1) = onnx::Mul(%674, %675), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %677 : Float(1, 1152, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%676, %encoder.blocks.12._se_expand.weight, %encoder.blocks.12._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %678 : Float(1, 1152, 1, 1) = onnx::Sigmoid(%677), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %679 : Float(1, 1152, 9, 2) = onnx::Mul(%678, %672), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %680 : Float(1, 192, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%679, %encoder.blocks.12._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %681 : Float(1, 192, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%680, %encoder.blocks.12._bn2.weight, %encoder.blocks.12._bn2.bias, %encoder.blocks.12._bn2.running_mean, %encoder.blocks.12._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %682 : Float(1, 192, 9, 2) = onnx::Add(%681, %663), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %683 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%682, %encoder.blocks.13._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %684 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%683, %encoder.blocks.13._bn0.weight, %encoder.blocks.13._bn0.bias, %encoder.blocks.13._bn0.running_mean, %encoder.blocks.13._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %685 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%684), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %686 : Float(1, 1152, 9, 2) = onnx::Mul(%684, %685), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %687 : Float(1, 1152, 13, 6) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%686), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %688 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1152, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%687, %encoder.blocks.13._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %689 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%688, %encoder.blocks.13._bn1.weight, %encoder.blocks.13._bn1.bias, %encoder.blocks.13._bn1.running_mean, %encoder.blocks.13._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %690 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%689), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %691 : Float(1, 1152, 9, 2) = onnx::Mul(%689, %690), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %692 : Float(1, 1152, 1, 1) = onnx::GlobalAveragePool(%691), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %693 : Float(1, 48, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%692, %encoder.blocks.13._se_reduce.weight, %encoder.blocks.13._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %694 : Float(1, 48, 1, 1) = onnx::Sigmoid(%693), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %695 : Float(1, 48, 1, 1) = onnx::Mul(%693, %694), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %696 : Float(1, 1152, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%695, %encoder.blocks.13._se_expand.weight, %encoder.blocks.13._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %697 : Float(1, 1152, 1, 1) = onnx::Sigmoid(%696), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %698 : Float(1, 1152, 9, 2) = onnx::Mul(%697, %691), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %699 : Float(1, 192, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%698, %encoder.blocks.13._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %700 : Float(1, 192, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%699, %encoder.blocks.13._bn2.weight, %encoder.blocks.13._bn2.bias, %encoder.blocks.13._bn2.running_mean, %encoder.blocks.13._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %701 : Float(1, 192, 9, 2) = onnx::Add(%700, %682), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %702 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%701, %encoder.blocks.14._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %703 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%702, %encoder.blocks.14._bn0.weight, %encoder.blocks.14._bn0.bias, %encoder.blocks.14._bn0.running_mean, %encoder.blocks.14._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %704 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%703), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %705 : Float(1, 1152, 9, 2) = onnx::Mul(%703, %704), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %706 : Float(1, 1152, 13, 6) = onnx::Pad[mode=\"constant\", pads=[0, 0, 2, 2, 0, 0, 2, 2], value=0](%705), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %707 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1152, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%706, %encoder.blocks.14._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %708 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%707, %encoder.blocks.14._bn1.weight, %encoder.blocks.14._bn1.bias, %encoder.blocks.14._bn1.running_mean, %encoder.blocks.14._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %709 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%708), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %710 : Float(1, 1152, 9, 2) = onnx::Mul(%708, %709), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %711 : Float(1, 1152, 1, 1) = onnx::GlobalAveragePool(%710), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %712 : Float(1, 48, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%711, %encoder.blocks.14._se_reduce.weight, %encoder.blocks.14._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %713 : Float(1, 48, 1, 1) = onnx::Sigmoid(%712), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %714 : Float(1, 48, 1, 1) = onnx::Mul(%712, %713), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %715 : Float(1, 1152, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%714, %encoder.blocks.14._se_expand.weight, %encoder.blocks.14._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %716 : Float(1, 1152, 1, 1) = onnx::Sigmoid(%715), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %717 : Float(1, 1152, 9, 2) = onnx::Mul(%716, %710), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %718 : Float(1, 192, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%717, %encoder.blocks.14._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %719 : Float(1, 192, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%718, %encoder.blocks.14._bn2.weight, %encoder.blocks.14._bn2.bias, %encoder.blocks.14._bn2.running_mean, %encoder.blocks.14._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %720 : Float(1, 192, 9, 2) = onnx::Add(%719, %701), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:172:0\n",
      "  %721 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%720, %encoder.blocks.15._expand_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_expand_conv] # ../efficientunet/layers.py:48:0\n",
      "  %722 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%721, %encoder.blocks.15._bn0.weight, %encoder.blocks.15._bn0.bias, %encoder.blocks.15._bn0.running_mean, %encoder.blocks.15._bn0.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %723 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%722), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %724 : Float(1, 1152, 9, 2) = onnx::Mul(%722, %723), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %725 : Float(1, 1152, 11, 4) = onnx::Pad[mode=\"constant\", pads=[0, 0, 1, 1, 0, 0, 1, 1], value=0](%724), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv]/ZeroPad2d[static_padding] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %726 : Float(1, 1152, 9, 2) = onnx::Conv[dilations=[1, 1], group=1152, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%725, %encoder.blocks.15._depthwise_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_depthwise_conv] # ../efficientunet/layers.py:48:0\n",
      "  %727 : Float(1, 1152, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%726, %encoder.blocks.15._bn1.weight, %encoder.blocks.15._bn1.bias, %encoder.blocks.15._bn1.running_mean, %encoder.blocks.15._bn1.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %728 : Float(1, 1152, 9, 2) = onnx::Sigmoid(%727), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %729 : Float(1, 1152, 9, 2) = onnx::Mul(%727, %728), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %730 : Float(1, 1152, 1, 1) = onnx::GlobalAveragePool(%729), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:768:0\n",
      "  %731 : Float(1, 48, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%730, %encoder.blocks.15._se_reduce.weight, %encoder.blocks.15._se_reduce.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_reduce] # ../efficientunet/layers.py:48:0\n",
      "  %732 : Float(1, 48, 1, 1) = onnx::Sigmoid(%731), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %733 : Float(1, 48, 1, 1) = onnx::Mul(%731, %732), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Swish[swish] # ../efficientunet/layers.py:14:0\n",
      "  %734 : Float(1, 1152, 1, 1) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%733, %encoder.blocks.15._se_expand.weight, %encoder.blocks.15._se_expand.bias), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_se_expand] # ../efficientunet/layers.py:48:0\n",
      "  %735 : Float(1, 1152, 1, 1) = onnx::Sigmoid(%734), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %736 : Float(1, 1152, 9, 2) = onnx::Mul(%735, %729), scope: EfficientUnet/Encoder[encoder]/MBConvBlock # ../efficientunet/layers.py:163:0\n",
      "  %737 : Float(1, 320, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%736, %encoder.blocks.15._project_conv.weight), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/Conv2dSamePadding[_project_conv] # ../efficientunet/layers.py:48:0\n",
      "  %738 : Float(1, 320, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%737, %encoder.blocks.15._bn2.weight, %encoder.blocks.15._bn2.bias, %encoder.blocks.15._bn2.running_mean, %encoder.blocks.15._bn2.running_var), scope: EfficientUnet/Encoder[encoder]/MBConvBlock/BatchNorm2d[_bn2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %739 : Float(1, 1280, 9, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%738, %encoder.head_conv.weight), scope: EfficientUnet/Encoder[encoder]/Conv2dSamePadding[head_conv] # ../efficientunet/layers.py:48:0\n",
      "  %740 : Float(1, 1280, 9, 2) = onnx::BatchNormalization[epsilon=0.001, momentum=0.99](%739, %encoder.head_batch_norm.weight, %encoder.head_batch_norm.bias, %encoder.head_batch_norm.running_mean, %encoder.head_batch_norm.running_var), scope: EfficientUnet/Encoder[encoder]/BatchNorm2d[head_batch_norm] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %741 : Float(1, 1280, 9, 2) = onnx::Sigmoid(%740), scope: EfficientUnet/Encoder[encoder]/Swish[head_swish] # ../efficientunet/layers.py:14:0\n",
      "  %742 : Float(1, 1280, 9, 2) = onnx::Mul(%740, %741), scope: EfficientUnet/SequentialConvTranspose2d[up_conv1] # ../efficientunet/layers.py:200:0\n",
      "  %743 : Float(1, 1280, 18, 2) = onnx::Concat[axis=2](%742, %742), scope: EfficientUnet/SequentialConvTranspose2d[up_conv1] # ../efficientunet/layers.py:201:0\n",
      "  %744 : Float(1, 1280, 18, 4) = onnx::Concat[axis=3](%743, %743), scope: EfficientUnet/SequentialConvTranspose2d[up_conv1] # ../efficientunet/layers.py:201:0\n",
      "  %745 : Float(1, 512, 18, 4) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1]](%744, %up_conv1.conv.weight, %up_conv1.conv.bias), scope: EfficientUnet/SequentialConvTranspose2d[up_conv1]/Conv2d[conv] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %746 : Float(1, 512, 17, 4) = onnx::Pad[mode=\"constant\", pads=[0, 0, -1, 0, 0, 0, 0, 0], value=0](%745), scope: EfficientUnet # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %747 : Float(1, 592, 17, 4) = onnx::Concat[axis=1](%746, %551), scope: EfficientUnet # ../efficientunet/efficientunet.py:168:0\n",
      "  %748 : Float(1, 512, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%747, %double_conv1.0.weight, %double_conv1.0.bias), scope: EfficientUnet/Sequential[double_conv1]/Conv2d[0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %749 : Float(1, 512, 17, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%748, %double_conv1.1.weight, %double_conv1.1.bias, %double_conv1.1.running_mean, %double_conv1.1.running_var), scope: EfficientUnet/Sequential[double_conv1]/BatchNorm2d[1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %750 : Float(1, 512, 17, 4) = onnx::Relu(%749), scope: EfficientUnet/Sequential[double_conv1]/ReLU[2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:912:0\n",
      "  %751 : Float(1, 512, 17, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%750, %double_conv1.3.weight, %double_conv1.3.bias), scope: EfficientUnet/Sequential[double_conv1]/Conv2d[3] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %752 : Float(1, 512, 17, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%751, %double_conv1.4.weight, %double_conv1.4.bias, %double_conv1.4.running_mean, %double_conv1.4.running_var), scope: EfficientUnet/Sequential[double_conv1]/BatchNorm2d[4] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %753 : Float(1, 512, 17, 4) = onnx::Relu(%752), scope: EfficientUnet/SequentialConvTranspose2d[up_conv2] # ../efficientunet/layers.py:200:0\n",
      "  %754 : Float(1, 512, 34, 4) = onnx::Concat[axis=2](%753, %753), scope: EfficientUnet/SequentialConvTranspose2d[up_conv2] # ../efficientunet/layers.py:201:0\n",
      "  %755 : Float(1, 512, 34, 8) = onnx::Concat[axis=3](%754, %754), scope: EfficientUnet/SequentialConvTranspose2d[up_conv2] # ../efficientunet/layers.py:201:0\n",
      "  %756 : Float(1, 256, 34, 8) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1]](%755, %up_conv2.conv.weight, %up_conv2.conv.bias), scope: EfficientUnet/SequentialConvTranspose2d[up_conv2]/Conv2d[conv] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %757 : Float(1, 256, 33, 8) = onnx::Pad[mode=\"constant\", pads=[0, 0, -1, 0, 0, 0, 0, 0], value=0](%756), scope: EfficientUnet # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %758 : Float(1, 296, 33, 8) = onnx::Concat[axis=1](%757, %514), scope: EfficientUnet # ../efficientunet/efficientunet.py:175:0\n",
      "  %759 : Float(1, 256, 33, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%758, %double_conv2.0.weight, %double_conv2.0.bias), scope: EfficientUnet/Sequential[double_conv2]/Conv2d[0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %760 : Float(1, 256, 33, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%759, %double_conv2.1.weight, %double_conv2.1.bias, %double_conv2.1.running_mean, %double_conv2.1.running_var), scope: EfficientUnet/Sequential[double_conv2]/BatchNorm2d[1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %761 : Float(1, 256, 33, 8) = onnx::Relu(%760), scope: EfficientUnet/Sequential[double_conv2]/ReLU[2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:912:0\n",
      "  %762 : Float(1, 256, 33, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%761, %double_conv2.3.weight, %double_conv2.3.bias), scope: EfficientUnet/Sequential[double_conv2]/Conv2d[3] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %763 : Float(1, 256, 33, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%762, %double_conv2.4.weight, %double_conv2.4.bias, %double_conv2.4.running_mean, %double_conv2.4.running_var), scope: EfficientUnet/Sequential[double_conv2]/BatchNorm2d[4] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %764 : Float(1, 256, 33, 8) = onnx::Relu(%763), scope: EfficientUnet/SequentialConvTranspose2d[up_conv3] # ../efficientunet/layers.py:200:0\n",
      "  %765 : Float(1, 256, 66, 8) = onnx::Concat[axis=2](%764, %764), scope: EfficientUnet/SequentialConvTranspose2d[up_conv3] # ../efficientunet/layers.py:201:0\n",
      "  %766 : Float(1, 256, 66, 16) = onnx::Concat[axis=3](%765, %765), scope: EfficientUnet/SequentialConvTranspose2d[up_conv3] # ../efficientunet/layers.py:201:0\n",
      "  %767 : Float(1, 128, 66, 16) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1]](%766, %up_conv3.conv.weight, %up_conv3.conv.bias), scope: EfficientUnet/SequentialConvTranspose2d[up_conv3]/Conv2d[conv] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %768 : Float(1, 128, 65, 16) = onnx::Pad[mode=\"constant\", pads=[0, 0, -1, 0, 0, 0, 0, 0], value=0](%767), scope: EfficientUnet # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %769 : Float(1, 152, 65, 16) = onnx::Concat[axis=1](%768, %477), scope: EfficientUnet # ../efficientunet/efficientunet.py:182:0\n",
      "  %770 : Float(1, 128, 65, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%769, %double_conv3.0.weight, %double_conv3.0.bias), scope: EfficientUnet/Sequential[double_conv3]/Conv2d[0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %771 : Float(1, 128, 65, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%770, %double_conv3.1.weight, %double_conv3.1.bias, %double_conv3.1.running_mean, %double_conv3.1.running_var), scope: EfficientUnet/Sequential[double_conv3]/BatchNorm2d[1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %772 : Float(1, 128, 65, 16) = onnx::Relu(%771), scope: EfficientUnet/Sequential[double_conv3]/ReLU[2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:912:0\n",
      "  %773 : Float(1, 128, 65, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%772, %double_conv3.3.weight, %double_conv3.3.bias), scope: EfficientUnet/Sequential[double_conv3]/Conv2d[3] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %774 : Float(1, 128, 65, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%773, %double_conv3.4.weight, %double_conv3.4.bias, %double_conv3.4.running_mean, %double_conv3.4.running_var), scope: EfficientUnet/Sequential[double_conv3]/BatchNorm2d[4] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %775 : Float(1, 128, 65, 16) = onnx::Relu(%774), scope: EfficientUnet/SequentialConvTranspose2d[up_conv4] # ../efficientunet/layers.py:200:0\n",
      "  %776 : Float(1, 128, 130, 16) = onnx::Concat[axis=2](%775, %775), scope: EfficientUnet/SequentialConvTranspose2d[up_conv4] # ../efficientunet/layers.py:201:0\n",
      "  %777 : Float(1, 128, 130, 32) = onnx::Concat[axis=3](%776, %776), scope: EfficientUnet/SequentialConvTranspose2d[up_conv4] # ../efficientunet/layers.py:201:0\n",
      "  %778 : Float(1, 64, 130, 32) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1]](%777, %up_conv4.conv.weight, %up_conv4.conv.bias), scope: EfficientUnet/SequentialConvTranspose2d[up_conv4]/Conv2d[conv] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %779 : Float(1, 64, 129, 32) = onnx::Pad[mode=\"constant\", pads=[0, 0, -1, 0, 0, 0, 0, 0], value=0](%778), scope: EfficientUnet # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %780 : Float(1, 80, 129, 32) = onnx::Concat[axis=1](%779, %459), scope: EfficientUnet # ../efficientunet/efficientunet.py:189:0\n",
      "  %781 : Float(1, 64, 129, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%780, %double_conv4.0.weight, %double_conv4.0.bias), scope: EfficientUnet/Sequential[double_conv4]/Conv2d[0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %782 : Float(1, 64, 129, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%781, %double_conv4.1.weight, %double_conv4.1.bias, %double_conv4.1.running_mean, %double_conv4.1.running_var), scope: EfficientUnet/Sequential[double_conv4]/BatchNorm2d[1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %783 : Float(1, 64, 129, 32) = onnx::Relu(%782), scope: EfficientUnet/Sequential[double_conv4]/ReLU[2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:912:0\n",
      "  %784 : Float(1, 64, 129, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%783, %double_conv4.3.weight, %double_conv4.3.bias), scope: EfficientUnet/Sequential[double_conv4]/Conv2d[3] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %785 : Float(1, 64, 129, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%784, %double_conv4.4.weight, %double_conv4.4.bias, %double_conv4.4.running_mean, %double_conv4.4.running_var), scope: EfficientUnet/Sequential[double_conv4]/BatchNorm2d[4] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %786 : Float(1, 64, 129, 32) = onnx::Relu(%785), scope: EfficientUnet/SequentialConvTranspose2d[up_conv_input] # ../efficientunet/layers.py:200:0\n",
      "  %787 : Float(1, 64, 258, 32) = onnx::Concat[axis=2](%786, %786), scope: EfficientUnet/SequentialConvTranspose2d[up_conv_input] # ../efficientunet/layers.py:201:0\n",
      "  %788 : Float(1, 64, 258, 64) = onnx::Concat[axis=3](%787, %787), scope: EfficientUnet/SequentialConvTranspose2d[up_conv_input] # ../efficientunet/layers.py:201:0\n",
      "  %789 : Float(1, 32, 258, 64) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1]](%788, %up_conv_input.conv.weight, %up_conv_input.conv.bias), scope: EfficientUnet/SequentialConvTranspose2d[up_conv_input]/Conv2d[conv] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %790 : Float(1, 32, 257, 64) = onnx::Pad[mode=\"constant\", pads=[0, 0, -1, 0, 0, 0, 0, 0], value=0](%789), scope: EfficientUnet # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:2848:0\n",
      "  %791 : Float(1, 34, 257, 64) = onnx::Concat[axis=1](%790, %input), scope: EfficientUnet # ../efficientunet/efficientunet.py:197:0\n",
      "  %792 : Float(1, 32, 257, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%791, %double_conv_input.0.weight, %double_conv_input.0.bias), scope: EfficientUnet/Sequential[double_conv_input]/Conv2d[0] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %793 : Float(1, 32, 257, 64) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%792, %double_conv_input.1.weight, %double_conv_input.1.bias, %double_conv_input.1.running_mean, %double_conv_input.1.running_var), scope: EfficientUnet/Sequential[double_conv_input]/BatchNorm2d[1] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %794 : Float(1, 32, 257, 64) = onnx::Relu(%793), scope: EfficientUnet/Sequential[double_conv_input]/ReLU[2] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:912:0\n",
      "  %795 : Float(1, 32, 257, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%794, %double_conv_input.3.weight, %double_conv_input.3.bias), scope: EfficientUnet/Sequential[double_conv_input]/Conv2d[3] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %796 : Float(1, 32, 257, 64) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%795, %double_conv_input.4.weight, %double_conv_input.4.bias, %double_conv_input.4.running_mean, %double_conv_input.4.running_var), scope: EfficientUnet/Sequential[double_conv_input]/BatchNorm2d[4] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1670:0\n",
      "  %797 : Float(1, 32, 257, 64) = onnx::Relu(%796), scope: EfficientUnet/Sequential[double_conv_input]/ReLU[5] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:912:0\n",
      "  %output : Float(1, 3, 257, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%797, %final_conv.weight, %final_conv.bias), scope: EfficientUnet/Conv2d[final_conv] # /home/jovyan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"effb0.onnx\"\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  dummy_input,                         # model input (or a tuple for multiple inputs)\n",
    "                  model_name,   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  verbose = True,\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size', 3 : 'n_frame'},    # variable lenght axes\n",
    "                                'output' : {0 : 'batch_size', 3 : 'n_frame'}}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as rt\n",
    "\n",
    "onnx_model = onnx.load('test_gpu.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
